---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

This website is currently under construction!
{: .notice}

I am a postdoctoral research fellow at the Computational and Biological Learning Lab (CBL) at the Department of Engineering of the University of Cambridge, where I am collaborating with Máté Lengyel and Yashar Ahmadian.

My research focuses on how neural circuits give rise to complex cognitive functions. For this I use theoretical and computational methods to investigate the computational principles of biological neural networks.
During my Ph.D., I showed how networks of excitatory and inhibitory neurons with rich computational functions can emerge from realistic plasticity mechanisms while the statistical structure of their inputs became reflected in their recurrent connectivity.
Currently, I work on generalising these models to episodic memory circuits in the hippocampus. My hope is that in the future, a better understanding of these circuits will help to understand why we remember some experiences but not others and how memory acquisition can be facilitated or disturbed.

See my [CV](/files/CV-2023.pdf) and the projects below for additional details.

## Projects

### “Synapse-type-specific competitive learning forms functional recurrent networks” — [Eckmann & Gjorgjieva, 2022, bioRxiv](https://www.biorxiv.org/content/10.1101/2022.03.11.483899v1).
Cortical networks exhibit complex stimulus-response patterns that are based on the recurrent interactions between ex- citatory and inhibitory neurons. However, it is unclear how the required synaptic connectivity can emerge from biological plasticity mechanisms. Using theory and modeling, we demonstrate how a wide range of cortical response properties can arise from Hebbian learning that is stabilized by the synapse-type-specific competition for synaptic resources. In plastic recurrent circuits, this competition enables the formation and decorrelation of inhibition-balanced receptive fields. Networks develop an assembly structure with stronger synaptic connections between similarly tuned neurons and exhibit response normalization and visual center-surround suppression. These results demonstrate how neurons can self-organize into functional networks and suggest an essential role for synapse-type-specific competitive learning in the formation of cortical circuits.

### “Active efficient coding explains the development of binocular vision and its failure in amblyopia” — [Eckmann et al., 2020, PNAS](https://www.pnas.org/doi/10.1073/pnas.1908100117).
Brains must operate in an energy-efficient manner. The classic efficient coding hypothesis states that sensory systems achieve this by adapting neural representations to the statistics of sensory input signals. Importantly, however, these
statistics are shaped by the organism’s behavior and how it samples information from
the environment. Therefore, optimal performance requires jointly optimizing neural
representations and behavior, a theory we call active efficient coding (Fig. 1). I tested the plausibility of this theory by proposing a computational model of the development of binocular vision. My model, for the first time, explains the self-calibration of accurate binocular vision under healthy conditions. In the case of refractive errors, however, the model develops into a state reminiscent of amblyopia, a leading cause of vision impairment, and suggests conditions for successful treatment.