---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

This website is currently under construction!
{: .notice}

I am a postdoctoral research fellow at the Computational and Biological Learning Lab (CBL) at the Department of Engineering of the University of Cambridge.
My research focuses on how neural circuits give rise to complex cognitive functions. I use theoretical and computational methods to investigate the computational principles of biological neural networks.
During my Ph.D., I showed how networks of excitatory and inhibitory neurons with rich computational functions can emerge from realistic plasticity mechanisms while the statistical structure of their inputs became reflected in their recurrent connectivity.
Currently, I work on generalising these models to episodic memory circuits in the hippocampus. In the future, a better understanding of these circuits will help to understand why we remember some experiences but not others and how memory acquisition can be facilitated or disturbed.
[See my CV for details](/files/CV-2023.pdf)

## Projects

### “Synapse-type-specific competitive learning forms functional recurrent networks” — [Eckmann & Gjorgjieva, 2022, bioRxiv](https://www.biorxiv.org/content/10.1101/2022.03.11.483899v1).
Cortical networks exhibit complex stimulus-response patterns. Previous work has identified the balance between excitatory and inhibitory currents as a central component of cortical computations, but has not considered how the required synaptic connectivity emerges from biologically plausible plasticity rules. Using theory and modeling, we demonstrate how a wide range of cortical response properties can arise from Hebbian learning that is stabilized by the synapse-type-specific competition for synaptic resources. In fully plastic recurrent circuits, this competition enables the development and decorrelation of inhibition-balanced receptive fields. Networks develop an assembly structure with stronger con- nections between similarly tuned neurons and exhibit response normalization and surround suppression. These results demonstrate how neurons can self-organize into functional circuits and provide a foundational understanding of plasticity in recurrent networks.

### “Active efficient coding explains the development of binocular vision and its failure in amblyopia” — [Eckmann et al., 2020, PNAS](https://www.pnas.org/doi/10.1073/pnas.1908100117).
Brains must operate in an energy-efficient manner. The classic efficient coding hypothesis states that sensory systems achieve this by adapting neural representations to the statistics of sensory input signals. Importantly, however, these
statistics are shaped by the organism’s behavior and how it samples information from
the environment. Therefore, optimal performance requires jointly optimizing neural
representations and behavior, a theory we call active efficient coding (Fig. 1). I tested the plausibility of this theory by proposing a computational model of the development of binocular vision. My model, for the first time, explains the self-calibration of accurate binocular vision under healthy conditions. In the case of refractive errors, however, the model develops into a state reminiscent of amblyopia, a leading cause of vision impairment, and suggests conditions for successful treatment.